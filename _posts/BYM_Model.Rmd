---
layout: post
title: "Spatial Relations and Besag-York-Mollie Framework"
author: "Rasim M Musal"
date: "2023-11-14"
output:
  html_document:
   theme: darkly
   highlight: espresso
   toc: true
   keep_md: yes
   toc_float: true
   toc_collapsed: false
   toc_depth: 2
   number_sections: true
   usemathjax: true
bibliography: bibliography.bib 
tags: [Besag-York-Mollie, Areal Data, Moran's I, Spatial Effect]
always_allow_html: true
---
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: { 
      equationNumbers: {
 
            autoNumber: "all",
            formatNumber: function (n) {return +n}
      } 
  }
});
</script>

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, echo=FALSE}
# A function for generating captions and cross-references

fig <- local({
    i <- 0
    list(
        cap=function(refName, text, center=FALSE, col="black", inline=FALSE) {
            i <<- i + 1
            ref[[refName]] <<- i
            css_ctr <- ""
            if (center) css_ctr <- "text-align:center; display:inline-block; width:100%;"
            cap_txt <- paste0("<span style=\"color:", col, "; ", css_ctr, "\">Figure ", i, ": ", text , "</span>")
            anchor <- paste0("<a name=\"", refName, "\"></a>")
            if (inline) {
                paste0(anchor, cap_txt)    
            } else {
                list(anchor=anchor, cap_txt=cap_txt)
            }
        },
        
        ref=function(refName, link=FALSE, checkRef=TRUE) {
            
            ## This function puts in a cross reference to a caption. You refer to the
            ## caption with the refName that was passed to fig$cap() (not the code chunk name).
            ## The cross reference can be hyperlinked.
            
            if (checkRef && !refName %in% names(ref)) stop(paste0("fig$ref() error: ", refName, " not found"))
            if (link) {
                paste0("<A HREF=\"#", refName, "\">Figure ", ref[[refName]], "</A>")
            } else {
                paste0("Figure ", ref[[refName]])
            }
        },
        
        ref_all=function(){
            ## For debugging
            ref
        })
})
library(knitr)
knit_hooks$set(plot = function(x, options) {
    sty <- ""
    if (options$fig.align == 'default') {
        sty <- ""
    } else {
        sty <- paste0(" style=\"text-align:", options$fig.align, ";\"")
    }
    
    if (is.list(options$fig.cap)) {
        ## options$fig.cap is a list returned by the function fig$cap()
        str_caption <- options$fig.cap$cap_txt
        str_anchr <- options$fig.cap$anchor
    } else {
        ## options$fig.cap is a character object (hard coded, no anchor)
        str_caption <- options$fig.cap
        str_anchr <- ""
    }
    
    paste('<figure', sty, '>', str_anchr, '<img src="',
        opts_knit$get('base.url'), paste(x, collapse = '.'),
        '"><figcaption>', str_caption, '</figcaption></figure>',
        sep = '')
    
})

rmdFn <- knitr::current_input()  # filename of input document

## Read lines and close connection
rmdCon <- file(rmdFn, open = "r")
rmdLines <- readLines(rmdCon)
close(rmdCon)

## Pull out all occurences of at least one back tick, followed 
## by any number of characters, followed by fig$cap (all on one line)
figscap_idx <- grep("`+(.*)fig\\$cap", rmdLines)
rmdLines <- rmdLines[figscap_idx]

## Get rid of everything up until the start of the caption label
## This presumes the caption label is the first argument of fig$cap()
## E.g., fig.cap = fig$cap("my_label", ...)
rmdLinesSansPre <- sub("(.*)fig\\$cap(.*?)[\"']", "", rmdLines)

## Identify everything up until the first quote
match_data <- regexpr("(.*?)[\"']", rmdLinesSansPre)

## Reduce the length by one, because we're not interested in the final quote
attr(match_data, "match.length") <- attr(match_data, "match.length") - 1

## Extract
fig_labels <- regmatches(rmdLinesSansPre, match_data, invert=FALSE)

if (length(fig_labels) > 0) {

    ## Test for duplicates
    if (anyDuplicated(fig_labels) > 0) stop("Duplicate caption labels detected")
    
    ## Create a named list of Figure numbers
    ref <- as.list(1:length(fig_labels))
    names(ref) <- fig_labels
}    
```
# Models Using Areal Data
In this section we will give a brief description of spatial models, and describe processes  which will eventually allow us to describe the Besag-York-Mollie model and its extensions.
An in depth introduction to many of the R related concepts we will discuss here is in [Crime Mapping Textbook](https://maczokni.github.io/crime_mapping_textbook/) 

We will first discuss Moran's I which provides an exploratory test for spatial relations. This is to be followed by a discussion involving the modeling of joint probability of spatial effects $\phi$. In addition we will illustrate how to prepare the data for STAN. 

# Moran's I 
When determining the presence of spatial relationships, a first step will be to determine whether there is reason to suspect that data that is in close proximity shows a recognizable pattern such that data which are closer to each other are more similar than data that are further apart. There are different frameworks in constructing spatial models. In this project we are interested in using areal data to create this framework.

Areal data, can be defined as data which is observed within well defined boundaries. For instance, square grids, zip code tabulation areas, or as in our project, counties in a particular state are all examples of well defined boundaries. Once we decide to use Areal data we need to assume a neighborhood structure. `r fig$ref("cal_map")` below will help illustrate this process. 


```{r include=FALSE}
a=knitr::include_graphics(rep("assets/img/countiesofcalifornia.png", 1))
```

```{r inline=TRUE,echo=FALSE}
a

```
`r fig$cap("cal_map", "FIPS numbers are recorded on each county", col="white", center=TRUE, inline=TRUE)`

Turn your attention to San Bernardino. It is surrounded by counties with Federal Information Processing Standard (FIPS) codes 27, 29, 37, 59, 65. These in turn are effected by other counties. Therefore there is a need to define what constitute a neighbor for a county and the weight of that neighborhood. These are all questions that can be quantified via a neighborhood matrix. There are different schemes in literature. However the Bayesian model that will follow is rather rich in terms of parameters we will use a binary neighborhood structure where if a county shares a border with another county its' effect is to be estimated. We will explain how to create and represent this matrix in STAN. Based on the neighborhood structure one of the first things to do would be to determine whether there is any spatial effects to model.


Moran's I is an exploratory index for spatial correlation and has a range between -1 and 1.   
Per @banerjee2003hierarchical Moran's I and its variance is;
\[
I=\frac{n}{W}\frac{\sum_{i}\sum_{j}w_{ij}(y_{i}-\bar y)(y_{j}-\bar y)}{(y_{i}-\bar y)^{2}}
\label{eq:I}
\]
\[
Var(I)=\frac{n^{2}(n-1)S_{1}-n(n-1)S_{2}-2S_{0}^{2}}{(n+1)(n-1)^{2}S_{0}^{2}}
\label{eq:VarI}
\]
where
\[
S_{0}=\sum_{i \ne j} w_{ij}, S_{1}=\frac{1}{2}\sum_{i \ne j}(w_{ij}+w_{ji})^{2},S_{2}=\sum_{k} \left( \sum_{j} w_{kj} + \sum_{i} w_{ik} \right)^{2}
\]
where;

* n is the number of areal components. (58 in California).

* $w_{ij}$ is the weight between areal unit i and j which for our purposes is either 0 or 1.

* W is the sum of weights in the neighborhood weight matrix (58).

$y_{i}$ is the quantity of interest in areal unit i.

$\bar y$ is the mean quantity.
Under the null hypothesis that there is no spatial correlation the expected Moran's I value would be equal to
\[E(I)=\frac{-1}{n-1}
\label{eq:EI}
\]
Once we have \eqref{eq:I}, \eqref{eq:VarI}, and \eqref{eq:EI} we can calculate a z score via
\[z=\frac{(I-E(I))}{\sqrt{(Var(I))}}
\label{eq:z}\]

and assuming Central Limit Theorem applies a hypothesis test can be performed. Per @banerjee2003hierarchical as convergence to normal distribution is harder for ratio of quadratic values, a large set of permutations involving areal units that lead to simulated Moran's I values can be obtained for more robust results. A new I value would be calculated for each areal permutation and the original I value can be compared against the randomly permuted areal units' I values. 

In understanding how this all works we need to look at some r code.

```{r, message=FALSE}
library(spdep)
library(spatialreg)
library(spatial)
library(tidyr)
library(ggplot2)
setwd("C:/Users/rm84/Desktop/research/HMM/data")
load("workspacewithbasedata.RData")
cnames=read.table("countynames.txt",sep="\t",header=TRUE)
```

```{r,warning=FALSE}
#shapeanddata is a simple features class object that contains 
#spatial information and county level feature information. 
#The poly2nb function creates the neighbor indexes 
nb_CA = poly2nb(shapeanddata)
#The neighbour indexes of county 1 in California (Alameda)
nb_CA[1]
#The nb2listw function will create a the weight list of neighbors for each county 
#Each neighboring county's weight is equally weighted. 
#Therefore the sum of all weights in each row is 1 and the sum of all weights 
#is the number of counties in California (58).     
colw <- nb2listw(nb_CA, style="W")
#Gives the list of weights for Alameda 1/N_{1} where N_{1} is the number of 
#Alameda neighbors. 1/length(nb_CA[1]) == 1/6
colw$weights[1]
```

We are going to set up some objects to calculate not just the I value but p value via 

1.  Hypothesis testing based on Central Limit Theorem. 
2.  Areal Unit Permutation. 

Note that the quantity of interest in our application is SMR of Covid-19 mortality rather than Covid-19 mortality itself. We find that this is more realistic to determine whether spatial structure exists as there are large fluctuations in Covid-19 mortality due to differences in population size. 

```{r, warning=FALSE}
#Number of permutations for 2. Areal Unit Permutation.
nsim <- 5000
#Random number seed
set.seed(1234)
# Number of Biweeks below N is the total number of counties in CA 58.
NumBiWeeks=77
#SMR is standardized mortality ratio observed/expected
SMR=array(dim=c(NumBiWeeks,N))
#Since E is calculated based on aggregate mortality in California and population size of each county SMR is better for investigating whether there is a spatial structure.
SMR=y/exp(log_E)
```

We already discussed how to calculate I in \eqref{eq:I}. Z score can be calculated via \eqref{eq:z}. We have 77 biweeks and for each biweek we are going to calculate 2 sets of p values associated with the Moran's I scores and visualize them across this time series. The objects, sim_pvalue and asympt_pvalue are going to contain the p values associated with permuted spatial neighborhoods and central limit theorem is assumed to hold, respectively. Since we hypothesize that like values are clustered together the p values are going to be calculated via $P(Z>z)$.     

```{r, warning=FALSE}
#Object where p values are calculated based on spatial neighborhood permutations
sim_pvalue=array(dim=c(NumBiWeeks))
#Object where p values are calculated based on assuming Central Limit Theorem applies
asympt_pvalue=array(dim=c(NumBiWeeks))
#Object that holds Moran's I values.
Ivalue=array(dim=c(NumBiWeeks))
#Hypothesis tests are directional as discussed above. The hardcoded values 58 can be parameterized to generalize. n stands for number of units S0 stands for total weight in the neighbourhood matrix. W and S_0 will have the same values.
for(i in 1:NumBiWeeks){
sim_pvalue[i]<-moran.mc(SMR[i,], listw=colw, nsim=nsim, alternative="greater")$p.value
asympt_pvalue[i]<-moran.test(SMR[i,],colw, alternative="greater", zero.policy=TRUE)$p.value
Ivalue[i]<-moran(SMR[i,],colw,n=58,S0=58)$I
}
#Number of hypothesis tests that have p values less than 0.05 (our pick of alpha)
sum(sim_pvalue<0.05)
sum(asympt_pvalue<0.05)
#Create a data frame to contain the created values 
moransdf=as.data.frame(matrix(nrow=NumBiWeeks,ncol=4))
moransdf[,1]=sim_pvalue
moransdf[,2]=asympt_pvalue
moransdf[,3]=Ivalue
moransdf[,4]=c(1:NumBiWeeks)  
#Name each column
names(moransdf)=c("p_value_mc","p_value_asymp","I_Value","Biweek")

#Create a data frame which will have 3 columns
#Biweek, the names which has the labels in quotes and the numbers recorded under #value 
moransdf_long <-moransdf %>% pivot_longer(c("p_value_mc","p_value_asymp","I_Value"),names_to = "names")
#Visualizing the values
ggplot(moransdf_long, aes(x=Biweek, y=value))+
geom_point(stat="identity")+
facet_wrap(~names,  ncol=1)+
scale_x_discrete(limits=c(1,5,10,15,20,25,30,35,40,45,50,55,60,65,70,75,77))+
xlab("Biweek t")
```

As we can see from the visualization of p values and the number of them below the arbitrary but often used alpha value of 0.05, that for majority of the time periods we can not refuse the null hypothesis that there is no spatial correlation in the areal units. On the other hand in nearly 30 of the biweeks the p values are less than 0.05 and after all, the I value is an exploratory measure.  We will describe building the spatial model in the next section.     

# The Joint Spatial Effect $\phi$

Once we determine what counts as a neighbor and that there is a spatial effect to account for, we will need to decide how to account for it. In doing so we will need to define 

\begin{equation}
P(\phi_{1},\ldots,\phi_{N}), 
\label{eq:joint} 
\end{equation}
where N is the number of areal units (i.e.: 58 counties in CA).
Writing this form is not trivial. Furthermore, if we want to take into account spatial relations, it is clear that this will not happen via $P(\phi_{1}) \times \ldots \times P(\phi_{N})$. It is standard in Bayesian applications to obtain this joint form from full conditional probabilities. However as @banerjee2003hierarchical discusses, these conditional probabilities can not be arbitrary and demonstrates the form they need to take to create a valid joint probability distribution \eqref{eq:joint}.    

## Markov Random Fields (MRFs)
Markov Random Fields (MRFs), a special stochastic process, provides an important method to create this joint distribution from conditional distributions. 
A good description of these mechanisms are described in @besag74 and @cressie2015statistics and an introductory set of illustrations can be [found here.](https://ermongroup.github.io/cs228-notes/representation/undirected/) MRFs, a set of random numbers, can be represented as undirected graphs with specific conditional independence properties. The main advantage of using MRFs is being able to use  spatial effect probabilities conditional on neighborhood structure rather than using all areal units in order to create the joint probability distribution.   


We will give a very brief introduction to these mechanism by first describing the term clique within the context of spatial analysis. We can define a clique as a set of areal units where each unit is a neighbor to all in the clique. For instance in figure `r fig$ref("cal_map")` Kern, Los Angeles, Ventura (County FIPS == 111) form a clique since they all share a boundary with each other. This is also the maximal clique since it is not a subset of another clique. 

Using MRFs' [properties](https://www.cs.cmu.edu/~16831-f14/notes/F11/16831_lecture07_bneuman.pdf) and their relationship to Gibbs distributions (Fields) we can use quadratic potentials between areal units to come up with the joint probability of all areal units.

\begin{equation}
p(\mathbf{\phi})=p(\phi_{1},\ldots,\phi_{N})=
\frac{1}{Z}exp\bigg[-\sum_{c_{i}\epsilon C}f_{i}(c_{i})\bigg],
\label{eq:cliques}
\end{equation}

where $c_{i}$ is 2 member cliques, $i$ is going to go from 1 to the total number of unique pairwise cliques and Z is a normalizing constant. We will expand more on this as we detail the code. For instance there is clique of county FIPS 29 (Kern) and 71 (San Bernardino). The function $f_{i}$, potentials between spatial areas will be based on squared differences on $\phi$ terms leading to the result; 
\begin{equation}
-\frac{1}{2} \sum (\phi_{i}-\phi_{j})^2
\label{eq:sqrddif}
\end{equation} 

where the index $i$ and $j$ are neighbors that form the clique. The detailed assumptions and restrictions given by @besag74 allow the normal distribution to describe the uncertainty in the joint distribution of $\phi$.  

In the [link](https://mc-stan.org/users/documentation/case-studies/icar_stan.html) we can see the linear algebra that shows the derivation of the potential function via the assumption of multivariate normal distribution with a mean of 0 for the joint probability of $\phi$. Note that the mean of 0 for $\phi$ is to ensure an identifiable joint distribution. Further discussion will await the code.

## Preparing the Areal Data for STAN

First we are going to create a neighborhood list using the poly2nb function from the spdep package.   
```{r}
nb_CA = poly2nb(shapeanddata)
print(nb_CA)
```

We obtain some information regarding our spatial object (graph object), namely that there are `r nbs$N`  areal units (counties) `r nbs$N_edges` shared borders. This means in a neighborhood `r nbs$N` by `r nbs$N` matrix, with (`r  nbs$N*nbs$N`) cells, `r nbs$N_edges` of the cells will have a non zero value. 
Furthermore the nb_CA object will contain neighborhood structure between counties. For instance; 
```{r}
nb_CA[[1]]
```
Shows that the first county 1,(`r cnames$C_Name[1]`) shares borders with counties 7 (`r cnames$C_Name[7]`), 38 (`r cnames$C_Name[38]`), 39 (`r cnames$C_Name[39]`), (41 `r cnames$C_Name[41]`), (43 `r cnames$C_Name[43]`) and (50 `r cnames$C_Name[50]`).

The pairwise cliques (neighbors) is obtained in r via the nb_data_funs functions provided by Mitzi Morris via the [github site](https://github.com/stan-dev/example-models/blob/master/knitr/car-iar-poisson/nb_data_funs.R). Among the many functions the author provides, an important one we will use is nb2graph.   

```{r}
nbs=nb2graph(nb_CA)

N = nbs$N
node1 = nbs$node1
node2 = nbs$node2
N_edges = nbs$N_edges
```

This function converts the spdep object into a form that will allow STAN to model the joint distribution of $\phi$. We will pass N as the number of areal units (counties) which is `r `nbs$N`. In addition node1 and node2 will contain information which will be used in computing $(\phi_{i} - \phi_{j})^2$.   

There are going to be `r nbs$N_edges` unique cliques (neighbor pairs), we will look at the first 10 such cliques below.
```{r}
node1[1:10]
node2[1:10]
```
As described above county 1,(`r cnames$C_Name[1]`), has `r length(nb_CA[[1]])` listed neighbors in node 2 corresponding to county 1 in node 1, which can be seen in the R output above. 

Once the spatial and covariate data is prepared for STAN by combining them into a list, it is exported via the stan_rdump function as a text-file via rstan package.  

```{r eval=FALSE}
dump=c('K','R','T','N','N_edges','node1','node2','log_E','y','x',
       'VacPop','medage','medsex','race',
       'scaling_factor','START','END')
#################################################
stan_rdump(dump, file = "C:/Users/rm84/Desktop/research/2023coviddata.r", append = FALSE,
           envir = parent.frame(),
           width = options("width")$width,
           quiet = FALSE)
```

# Besag York Mollie (BYM) Model
BYM model was first implemented in @besag1991bayesian which has a log linear Poisson likelihood. The original form of the distribution can be stated as;     

\begin{equation}
Y_{i} \sim Poisson(\lambda_{i}) \\
log(\lambda_{i}) = log(E_{i})  \times (\beta*X_{i}+\theta_{i}+\phi_{i}),  
\end{equation}

where $\phi$, areal spatial effect, has the form as described via \eqref{eq:sqrddif}. It will be a vector with N elements same as $\theta$, the specific random effects of the areal units. In this post we will ignore the original model and focus on the extended version

\begin{equation}
Y_{it} \sim Poisson(\lambda_{i}) \\
log(\lambda_{i}) = log(E_{i})  \times \left(\beta*X_{i}+\left(\sqrt{\frac{\rho}{s}}\times \phi_{i}+\sqrt{(1-\rho)}\times \theta_{i}\right)\times \sigma \right),
\label{eq:lambda}
\end{equation}

* $\rho \in [0,1]$ controls the contribution of spatial vs random effects. If $\rho$ is 0, 
* s is the scaling factor which can be computed using the  and the function provided by once again Mitzi Morris and the [github site](https://github.com/stan-dev/example-models/blob/master/knitr/car-iar-poisson/nb_data_funs.R). The constant value is evaluated from the matrix $Q$ and for ICAR models it is equal to 
\[Q=D(I-A)\]
where 
* D is the N by N diagonal matrix with the number of neighbors for each areal unit.
* I is the N by N identity matrix. 
* A is the N by N adjacency matrix.  
Using these matrices as input, the function "scale_nb_components" calculates the geometric mean of the variances which are on the diagonal of $Q^{-1}$ matrix diagonal. This in turn ensures that the prior of $\phi$ will have a standard deviation of 1. We will also set the prior of $\theta$ as 1. This is necessary to be able to interpret $\sigma$ as the overall standard deviation of combined $\phi$ and $\theta$ terms.  

We will include a time component t which will modify the equation. For now we will focus on STAN program. 

## STAN program and BYM Original and Extended Version
In this section we explain how to setup and execute the Besag York Mollie model. Most of this section is paraphrased from [here](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6830524/), where the analysis is based on a single slice of time. The authors explain the original formulation for BYM which have convergence issues and propose a new solution. 

## STAN Function for $\phi$
An elaborate explanation of the function created in STAN for $\phi$ exists [here](https://mc-stan.org/users/documentation/case-studies/icar_stan.html#adding-an-icar-component-to-a-stan-model). 

```{stan, eval=FALSE, output.var="function"}
functions {
  real icar_normal_lpdf(row_vector phi, int N, int[] node1, int[] node2) 
  {
    return -0.5 * dot_self(phi[node1] - phi[node2])
    + normal_lpdf(sum(phi) | 0, 0.0001 * N);
  }
          }
```

The dot_self function, multiplied with -0.5 is the application of equation  \eqref{eq:sqrddif}. It should be noted here that the variable declared as sum of $\phi$ on the last line of the puts a soft constraint on the mean of $\phi$ vector of 0 with a standard deviation of 0.0001. 

## STAN Data/Transformed Section
The data  section will include the time index extending the research explained so far. The STAN program has comments next to these constants that are self explanatory.  The matrix y are the mortality values aggregated in   biweeks^[https://data.chhs.ca.gov/dataset/covid-19-time-series-metrics-by-county-and-state] from the daily data obtained from California Health and Human Services is between 2020-02-01 and 2023-01-17. We will remove the last 16 days of observation from the analysis. The first day of 2023 (Sunday) to is contained in the last observed biweek of 2022. 

The Gini inequality is obtained from American Community Survey data^[https://data.census.gov/table/ACSDT5Y2022.B19083?q=inequality%20in%20counties%20of%20california&g=040XX00US06$0500000]. Gini inequality is a number that goes between 0 and 1, 0 indicating every individual element (household) having the same income and 1 indicating the maximum possible inequality between the households. Gini inequality can have 1 and 5 year estimates, we use the 5 year estimates in this research.

```{r, warning=FALSE}
library(ggplot2)
library(viridis)
library(cowplot)
library(ggspatial)
library(ggpubr) 

wd="C:/Users/rm84/Desktop/research/HMM/data/"
setwd(wd)
GINI=read.table("gini20and21and22.csv",header=TRUE,sep=",")
attach(GINI)
map_GINI20=ggplot() +
  annotation_spatial(shapeanddata) +
  ggtitle("Gini 2020")+
  theme(plot.title = element_text(hjust = 0.5))+
  layer_spatial(shapeanddata, aes(fill = (Gini_Index_2020)))+
  theme(legend.title= element_blank())+
  labs(fill = "GINI. 20")+scale_fill_viridis(limits = c(0.39,0.6),direction=-1)+
  theme(legend.position = "none")

map_GINI21=ggplot() +
  annotation_spatial(shapeanddata) +
  ggtitle("Gini 2021")+
  theme(plot.title = element_text(hjust = 0.5))+
  layer_spatial(shapeanddata, aes(fill = (Gini_Index_2021)))+
  theme(legend.title= element_blank())+
  labs(fill = "GINI. 21")+scale_fill_viridis(limits = c(0.39,0.6),direction=-1)+
  theme(legend.position = "none")

map_GINI22=ggplot() +
  annotation_spatial(shapeanddata) +
  ggtitle("Gini 2022")+
  theme(plot.title = element_text(hjust = 0.5))+
  layer_spatial(shapeanddata, aes(fill = (Gini_Index_2022)))+
  theme(legend.title= element_blank())+
  labs(fill = "GINI. 22")+scale_fill_viridis(limits = c(0.39,0.6),direction=-1)+
  theme(legend.position = "none")
              
ggarrange(map_GINI20,map_GINI21,map_GINI22,nrow=1,ncol=3,common.legend = TRUE, legend="bottom")

```

In this particular plot we see the changes in the GINI inequality measures collected across the counties of California across 5 years across 2020 to 2022.   

We also obtain daily fully vaccinated individuals' data in the counties and convert it to biweekly rates of vaccinated population. This assumes the location people get vaccinated is in the county of their residence. The Covid-19 vaccine has been available only since December 2020 in California therefore the percentage is entered as 0 percent for the previous biweeks. 

```{stan, eval=FALSE, output.var="data"}
data { 
  int<lower=1> T;//number of time periods
  int<lower=1> R;//number of races specified in dataset
  int START; //time period analysis will start from 
  int END; // time period analysis will stop at
  int<lower=0> N;//number of spatial areas
  int<lower=0> N_edges; //number of shared borders between counties
  int<lower=1, upper=N> node1[N_edges];  // node1[i], node2[i] neighbors
  int<lower=1, upper=N> node2[N_edges];  // node1[i] < node2[i]
  int<lower=0>  y[T,N];              // count outcomes across T time periods
  real  x[167,N];              // covariates which also include interaction effects
  matrix [T,N] log_E; // logarithm of the expected mortality values if mortality risk was uniformly applied 
  vector [N] VacPop[T] ; // Vaccinated population percentage in the county. Changes with biweeks 
  real<lower=0> scaling_factor;  // scales the variance of the spatial effects
  vector [N] medage; // standardized median age
  vector [N] medsex; // sex (coded as dummy)
  matrix [R,N] race; // percentage of races in counties
}

transformed data {
  //Providing a matrix with a single index returns the specified row. For instance, if m is a matrix, then m[2] is the second row. 
//using the covariates matrix X to create specific matrices   
//t = 1 to 25 is 2020
//t = 26 to 51 is 2021
//t = 52 to 77 is 2022
matrix [T,N] poverty;
matrix [T,N] income;
matrix [T,N] povinc;
matrix [T,N] gini;
int ITER=END-START+1; 
  row_vector[N] white=race[2];
  row_vector[N] nonwhite=1-race[2];
poverty[26:51] =rep_matrix(to_row_vector(x[2]), 26);
poverty[52:77] =rep_matrix(to_row_vector(x[3]), 26);
income[1:25] =rep_matrix(to_row_vector(x[4]), 25);
income[26:51] =rep_matrix(to_row_vector(x[5]), 26);
income[52:77] =rep_matrix(to_row_vector(x[6]), 26);
povinc[1:25] =rep_matrix(to_row_vector(x[8]), 25);
povinc[26:51] =rep_matrix(to_row_vector(x[9]), 26);
povinc[52:77] =rep_matrix(to_row_vector(x[10]), 26);
gini[1:25] =rep_matrix(to_row_vector(x[11]), 25);
gini[26:51] =rep_matrix(to_row_vector(x[12]), 26);
gini[52:77] =rep_matrix(to_row_vector(x[13]), 26);
}


```

## STAN Parameter/Transformed Section
In this section we specify the parameters that we will keep track of. The parameters that are to be dynamically estimated is in transformed parameters section. We define $\sigma$ of \eqref{eq:lambda} as the single dimensional array sigma with ITER elements,$ ITER==(T-1)==77-1$, making explicit the choice that we shall estimate the parameter at every t. The parameter gamma_vac is going to be used to estimate beta_vac the coefficient effect of vaccinations. The spatial effect $\phi$ is a row vector with N (58) elements. The parameter which quantifies the trade-off between spatial effect $\phi$ and $\theta$ is created as an array of size ITER, rho ($\rho$), which will also be estimated at every iteration t. The intercept parameter array, beta_int has the same number of elements as rho array. The rest of the coefficients are associated the covariates written next to "beta".    
The ITER (76) sized array theta contains a matrix of size 1 and N (1,58). It represents $\theta$, random effects.      

In the transformed parameters section, the first object created is the object alpha. This is an array of ITER size where each element is a matrix of "1,N" (1,58) dimensions. This object is where the equation \eqref{eq:lambda} is going to be evaluated. The beta_vac array is an array of size ITER and is calculated as
\[
\beta_{vac_{1}}=\gamma_{1} \\
\beta_{vac_{t}}=\beta_{vac_{t-1}}+\gamma_{t}
\label{eq:vac}
\]

The for loop involving beta_vac is the one associated with \eqref{eq:vac}.
The next for loop calculates concolved_re

\begin{equation}
\left(\sqrt{\frac{\rho}{s}}\times \phi_{i}+\sqrt{(1-\rho)}\times \theta_{i}\right)\times \sigma
\end{equation}

which is the combination of spatial and random effect in the \eqref{eq:lambda} and is evaluated in to the matrix object with ITER and N rows, columns respectively.  

In the final stage alpha array of ITER size where every element is a matrix of 1,N (1,58) dimensions is evaluated. 
```{stan, eval=FALSE, output.var="parameters"}
parameters {
  real <lower = 0> sigma [ITER];
 real gamma_vac[ITER];
   row_vector[N] phi;
  real<lower=0,upper=1> rho[ITER];
  matrix [ITER,N] theta;
real beta_int[ITER];
real beta_pov;
real beta_inc;
real beta_dens;
real beta_gini;
real beta_age;
real beta_sex;
real beta_white;
}
transformed parameters {
  matrix[1,N] alpha [ITER] ;
  real beta_vac[ITER];


beta_vac[1]=gamma_vac[1];    
  {
    matrix [ITER,N] convolved_re;
   
    for(t in START:ITER) {
      beta_vac[t]=beta_vac[t-1]+gamma_vac[t];}
      
for(t in START:END){
      convolved_re[t-START+1] = (sqrt(rho[t-START+1] / scaling_factor) * phi + sqrt(1 - rho[t-START+1]) * theta[t-START+1])*sigma[t-START+1]; 
      alpha[t-START+1][1,1:N]=exp(
                                  log_E[t,1:N]+
                                  to_row_vector(convolved_re[t-START+1])+
                                    beta_int[t-START+1]+
                                    beta_pov*poverty[t]+
                                    beta_inc*income[t]+
                                    beta_dens*to_row_vector(x[7])+
                                    beta_gini*gini[t]+
                                    beta_vac[t-START+1]*to_row_vector(VacPop[t-1])+
                                    beta_age*to_row_vector(medage)+
                                    beta_sex*to_row_vector(medsex)+
                                    beta_white*to_row_vector(white)
                                    ); 
                                   
    }
 
  }
}
```

# References

